---
layout: post
comments: true
title: The Fourier Transform (AP186 A5)
tags: AP186
---  

In this post, I take a look at the Fourier transform (in particular, the discrete *Fast Fourier Transform* or FFT implementation available in many programming languages), as well as its effects and applications in the realm of imaging. Exciting!

So what is the Fourier transform?

![smbcfourier](http://www.smbc-comics.com/comics/20130201.gif)
*No, it's not this. ([Saturday Morning Breakfast Cereal](http://www.smbc-comics.com/comic/2013-02-01) by Zach Weinersmith)*

In simple terms, the Fourier transform of a function is its representation in terms of its constituent frequencies; as if it were represented as a sum of various sinusoidal functions. In integral form, it is given (*Arfken* 6th ed., 15.2),

$$g(\omega) = \frac{1}{\sqrt{2\pi}}\int_{-\infty}^{\infty}f(t)e^{i\omega t} dt.$$

From the equation, we can see that it transforms functions that vary temporally (or spatially, by replacing \\(t\\) with \\(x\\)) into a periodic function that acts with a given frequency.

## FFT and the discrete Fourier transform

The Fourier transform assumes that you have a continuous function, but a lot of the data that we can work with on a computer is *discrete*, where you have a list of singular values at certain intervals, and not continuous functions! Images in particular are themselves discrete in the \\(x\\) and \\(y\\) directions; it's not exactly easy to try and represent your holiday photo as a single continuous function.

A discrete version of the Fourier transform, for a series of \\(N\\) discrete points, is given (*Arfken* 6th ed., 14.87 modified),

$$g(\omega_p) = \frac{1}{2N}\sum_{k = 0}^{2N-1}f(t_k)e^{i\omega_p t_k}.$$

It should be noted that while this allows for the numerical calculation of the Fourier transform on a computer, the discrete Fourier transform has certain limits. For instance, it fails to aliasing on a series that has poor resolution, which could hide a higher frequency from being manifested.

Most programming languages and operating systems have support for a highly optimized algorithm for the discrete Fourier transform, called the *Fast Fourier Transform* or FFT, presented by Cooley and Tukey in 1965 ([J. W. Cooley and J. W. Tukey, *Math. Comput.* 19: 297 (1965)](http://www.ams.org/journals/mcom/1965-19-090/S0025-5718-1965-0178586-1/)). The introduction of FFT is said to have reduced the computing cost of taking the Fourier transform of a series to requiring only \\((N/2)\log_2N\\) calculations instead of \\(N^2\\), for \\(N\\) being a power of 2.

In Scilab with SIVP, you can load images using the `imread()` function, which would subsequently convert it into a matrix of intensity values. With these loaded images or a synthetic image, one can easily obtain the 2D FFT with the function `fft2()`. The following code block, for instance, displays the Fourier transform of a small synthetic image of an aperture.

```matlab
nx = 512
ny = 512
x = linspace(-1,1,nx);
y = linspace(-1,1,ny);
[X,Y] = meshgrid(x,y);
r = sqrt(X.^2 + Y.^2);
circle = zeros(size(X,1), size(X,2));
circle(find(r <= 0.2)) = 1.0;
imshow(circle)
```

![circleap.png](https://s18.postimg.org/bqnr8xqpl/circleap.png)

The resulting Fourier transform of the above aperture is that of an Airy pattern, analogous to its physical manifestation in optics by focusing light through a real aperture.

```matlab
FIgray = fft2(double(circle));
process = fftshift(abs((FIgray)));
process = 255*abs(process)/max(abs(process));
imshow(uint8(process))
```

![circapfft.png](https://s12.postimg.org/jkst39a8t/circapfft.png)

Note that without the `fftshift()` function, the image will be displayed with inverted axes (the center parts of the image will appear at the corner points, for instance), where the peaks of the Airy pattern are at the four corners.

![circapfftnoshift.png](https://s13.postimg.org/61uwh5kpj/circapfftnoshift.png)

If we were to take the inverse Fourier transform of the FFT image (by simply running `fft2()` on it once more), we return to our original aperture:

```matlab
imshow(fft2(process))
```

![circapfftinv.png](https://s13.postimg.org/5pammx00n/circapfftinv.png)

Of course, we don't have to work exclusively with apertures; we can just as easily get the FFT of any two-dimensional array. That of the letter *A*, for example:

![lettera.png](https://s16.postimg.org/umbp942ed/lettera.png)

We then apply the FFT on several synthetic images. Several properties of the FFTs shown, such as its anamorphic properties, will be discussed in further detail in the next blog post.

### Corrugated roof (sinusoid along \\(x\\))

![corrroof.png](https://s17.postimg.org/om7ey1j27/corrroof.png)

The Fourier transform of a sinusoid manifests at two peaks at the frequency of the sinusoid with respect to the origin. Note that the peaks appear small due to the FT's anamorphic property, where features that are large in the spatial domain manifest much smaller in the frequency domain, and vice versa.

### Double slit

![dslit.png](https://s10.postimg.org/gs3gmmoxl/dslit.png)

The resulting FFT shows a sinusoid along one axis that appears convolved with a \\(\mathbf{sinc}\\) function varying its intensity along that same axis.

### Square aperture

![sqap.png](https://s22.postimg.org/mv5yk5onl/sqap.png)

The square aperture manifests similarly to the Airy pattern, but with the ringing only along the edges of the square.

### Gaussian aperture

![gaussap.png](https://s9.postimg.org/vgql0xaan/gaussap.png)

The Fourier transform of the gaussian aperture is a near exact single point in the center of the image. Note that (b) is zoomed in due to the FT's anamorphic property, with some visible artifacts around the point.

## Convolution and the simulation of an imaging device

In this case of manipulating digital images, convolution is performed by taking the element-by-element product of two matrices of similar dimensions. Convolutions can act as a filter: matrix elements convolved with a zero are effectively filtered out, as they appear zero in the final product, while convolving with a higher value can enhance certain features represented by that element. Below, I perform a quick demonstration of such an example of filtering.

The letters **VIP** were placed as part of a synthetic image to represent an *object*. By convolving a circle with the FFT of the object, we can simulate the 'projection' of that object through an aperture or imaging device.

![imagingcircles.png](https://s12.postimg.org/yagv5dov1/imagingcircles.png)
*Multiple examples involving different circle sizes and their resulting images.*

It could be said that convolving the circle image with the Fourier transform acts as a low-pass filter, as it only allows low-frequency features to pass, which are, in a sense, those features near the center of the FFT-shifted transform image. Increasing the size of the circle allows higher frequency features to exhibit themselves, as evident in the images. Higher-frequency sinusoidal ringing is much more evident in the larger-aperture images, whereas low-frequency ringing is seen in the small-aperture images.

I happened to have a pinhole camera on hand with multiple apertures, and by taking a few sample images, it is shown that in real life, adjusting the aperture of your camera system directly affects the quality of your projected image. Shown in (a) and (b) below are real projected images of our *object* (displayed with maximum brightness on a laptop screen) through a small aperture and a larger aperture respectively. Here it is obvious that a smaller aperture produces sharper but dimmer images, while that of a larger aperture creates much brighter images, but with a catch: the images are less sharp. Note that only the contrast has been adjusted to improve visualization.

![realap.png](https://s22.postimg.org/l71dzz9wh/realap.png)

It is interesting to note that this aperture variation, used in the physical realm of optics, is not completely analogous to the circles used earlier in the FFT. The earlier circles filtered directly in the frequency domain, while the aperture filters in a spatial sense. It could be said that the spatial equivalent of the large-aperture in the frequency domain is manifested as a small aperture, and vice-versa, once again due to the Fourier transform's anamorphic property. This means that (a)'s spatially small aperture filters like a large aperture in the frequency domain, while (b)'s spatially large one only allows the lowest of frequencies as it is a small diameter circle in frequency space.

## Template matching and correlation

Another application of the FFT and convolution is in one version of template matching, where one attempts to find a small sample of an image, be it a pattern or object, in a larger, more complex image. By convolving the respective Fourier transforms of a base image and a pattern that you seek to find, you highlight the frequency peaks of the base image with the frequencies evident in the pattern. Getting the inverse transform of the resulting convolved image will then give you the spatial locations of where the pattern occurs.

As an example, below is a sample image with the text *THE RAIN IN SPAIN STAYS MAINLY IN THE PLAIN* (a). Here we template match the letter *A* in the base image (b). The resulting inverse transform of the convolution is in figure (c&zwnj;).

![spainrain.png](https://s14.postimg.org/aeq6wrphd/spainrain.png)

It is evident that the peaks of (c&zwnj;) are the locations where the pattern of *A* is most evident, and thus correspond to the locations of *A*. Much fainter areas are where there are letters of a similar form to *A*, but not completely *A*-like, such as the diagonal elements of the letters *M*, *N*, and *Y*.

Template matching could be used as a rudimentary form of OCR or optical character recognition, which involves the digitizing of text in an image where a computer program might try to recognize the characters.

To demonstrate this, I applied distortion and distracting elements to the text while trying to maintain its legibility; these are basic techniques in generating [CAPTCHAs](https://en.wikipedia.org/wiki/CAPTCHA), which are intentionally designed to make it harder for a program to perform OCR and determine the text; a type of "reverse Turing test."

![captcha.png](https://s11.postimg.org/6qv4i8rc3/captcha.png)

From the results, we can see that the only peaks exhibited in (b) are those that have little distortion applied to them, while the strongly distorted *A*s lack any peaks in the correlation image. We can see that this form of template matching is only robust if the form and orientation is preserved and strongly evident. Another way this can fail is if the font of the text used to match is wildly different from that used in the text, or the case of multiple font faces being used.

## Edge detection through convolution

As an extension to template matching, we can attempt to template match an edge in an object through convolution with an edge pattern. For instance, the edge pattern matrix,

$$ \begin{pmatrix} -1 & -1 & -1 \\ 2 & 2 & 2 \\ -1 & -1 & -1 \end{pmatrix} $$

entered into Scilab as `epattern = [-1 -1 -1; 2 2 2; -1 -1 -1]`, corresponds to a horizontal edge. Convolving it with the VIP image shows highlighted areas along the edges of the letters.

![viphedge.png](https://s10.postimg.org/hap4hl4nt/viphedge.png)

This can apply for other edge patterns, such as vertical, diagonal, and central pattern matrices. A few examples are shown in the composite image below.

![vipedge.png](https://s22.postimg.org/q1dtmgyj5/vipedge.png)

Note that if we were to threshold the "edge" given by a single edge pattern convolution, not all edges of the text are visible. We can overlay a combination of different edge patterns thresholded so that we can obtain a reasonable edge image.

We extend this to attempting edge detection on a sample test image. The different patterns were tried on the image to see how they act on edge detection. The test image used for this part is a scanned photo of a house.

![house](https://upload.wikimedia.org/wikipedia/commons/thumb/5/5a/%224%2C000_Unit_Housing_Project_Progress_Photographs_March_6%2C1943_to_August_11%2C_1943%2C_Construction_of_Fire_House..._-_NARA_-_296754.tif/lossy-page1-2560px-%224%2C000_Unit_Housing_Project_Progress_Photographs_March_6%2C1943_to_August_11%2C_1943%2C_Construction_of_Fire_House..._-_NARA_-_296754.tif.jpg)
*Public domain image from [Wikimedia Commons](https://commons.wikimedia.org/wiki/File:%224,000_Unit_Housing_Project_Progress_Photographs_March_6,1943_to_August_11,_1943,_Construction_of_Fire_House..._-_NARA_-_296754.tif).*

The same four patterns were convolved with the test image and, as shown below, their edges are clearly highlighted.

![houseedge.png](https://s4.postimg.org/neup6f73h/houseedge.png)

Thresholding will highlight the evident edges of the image. The following image is each thresholded edge convolution overlaid on top of one another. Note the appearance of the edges of the windows, the siding, and the front lawn path in the thresholded image.

![houseedgeoverlaysthresh.png](https://s22.postimg.org/vfocp9soh/houseedgeoverlaysthresh.png)

It might not be perfect, however, it's a simple application and can be made to work well for several combinations of thresholded results from different edge matrices.

----

This activity took me much longer than I originally anticipated to write out, due to the different exploratory segues I took, and further reading to allow me to completely grasp, understand, and explain the new topic to the best of my knowledge. For the self-evaluation, I would give myself a **9/10**.

I would also like to acknowledge Louie Rubio for his insights while I was writing out the part concerning the simulation of an imaging device. External references used are linked in their appropriate sections. Additionally, the primary reference used for the introduction regarding the Fourier transform, DFT, and FFT, is Chapters 14 and 15 of Arfken and Weber's *Mathematical Methods for Physicists*, sixth edition.
