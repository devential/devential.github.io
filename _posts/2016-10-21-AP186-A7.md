---
layout: post
comments: true
title: Image Segmentation (AP186 A7)
tags: AP186
---  

A basic tool in digital image processing is segmentation, which is the separation of a certain region-of-interest from a background. Several methods exist that can automatically or manually segment an image, stemming from the multitude of possible features that can be extracted from them.

One of the simplest ways to segment an image is through thresholding of grayscale levels. This would be useful if your region of interest has good contrast from the rest of your image, such as in the case of text on paper. The following grayscale image of a check is an ideal case of this, as we can easily filter out the textual elements given the proper treshold from the paper:

![cropped_grayscale_check.jpg](https://s14.postimg.org/4wzlodfsx/cropped_grayscale_check.jpg)

Selecting the appropriate threshold may be done through trial and error, or by studying the image's grayscale histogram:

![a7aghist.png](https://s11.postimg.org/uyclc0aub/a7aghist.png)

The peak closer to an intensity of 255 (which is white for an 8-bit image) shows that a large part of our image is composed of light gray to white pixels. Inspection of the original image shows that this would likely correspond to the light-gray paper background. setting a threshold at pixel value 125 for instance allows us to filter to black all pixels above this value, with the remaining pixels below the value being considered part of the signal (and are thus made white). For this image, it results in a nicely segmented binary image with which we can perform further processing.

![a7athresh125.png](https://s11.postimg.org/olphslp9f/a7athresh125.png)

Adjusting the threshold, of course, allows you to include greater or fewer intensity values as part of your binary image. However, a too high threshold may cause you to include noise from the paper, while a too low threshold may not include all textual elements. The following animation illustrates this, where the number in the lower-left hand corner denotes the threshold value:

![thresh.gif](https://s21.postimg.org/47blsvvfr/thresh.gif)

This method of segmentation fails, however, when trying to separate areas with similar gray-level contrast. Such is the case as when two areas in an image have different colors but similar gray-level intensities. An example would be the following photo of a rugby game:

![rugbysmall.jpg](https://s21.postimg.org/93f97ms4n/rugbysmall.jpg)
*Public domain image from Wikimedia Commons ([link](https://commons.wikimedia.org/wiki/File:USO-FCG_-_20140913_19.jpg))*

If we were to segment, say, the blue team jerseys by simply using grayscale intensities, we would not be able to sufficiently segment it without including portions of the red team's jerseys, as they have a similar grayscale intensities. This is observed by simply converting it to grayscale:

![rugbygraysmall.jpg](https://s11.postimg.org/wq41gn9oz/rugbygraysmall.jpg)

Simply thresholding the image thus does little in the way of separating blue team jerseys from red's. Not only that, but there is also plenty of noise from the surrounding environment:

![rugbythresh.png](https://s21.postimg.org/ez3fyy7dz/rugbythresh.png)

A solution to this is through color image segmentation, where we segment the image in color space rather than in its grayscale intensity. One such representation of color is through normalized r-g chromaticity coordinates, or NCC, where we define intensity *I* as the sum of *R*, *G*, and *B* values in a pixel:

$$I = R + G + B$$

We then define the chromaticity coordinates *r*, *g*, and *b* which are the values of the *R*, *G*, and *B* color channels respectively divided by *I*, hence the word *normalized* in NCC:

$$r = \frac{R}{R+G+B} = \frac{R}{I}$$

$$g = \frac{G}{I}$$

$$b = \frac{B}{I}$$

Because of this definition, we can note that \\(r + g + b = 1\\), which is equivalent to, with a few transpositions,  \\(b = 1 - r - g\\). Being able to represent *b* in terms of *r* and *g* reduces the number of variables required to describe a color. Ultimately, using solely *r* and *g*, we can represent chromaticity on a two-dimensional plane independent of the intensity I. If we were to factor in intensity, it would run along the z-axis of the r-g chromaticity plane, extending it to three dimensions. This would be analogous to the color's lightness.

Normalized r-g chromaticity coordinates allow us to segment color in two dimensions, as color may now be described in terms of two variables (*r* and *g*) instead of three (*R*, *G*, and *B*). This also allows us to describe color independent of its lightness or shading, as objects with a solid color may manifest with multiple shades depending on the ambient lighting. This property will be convenient as it does not just consider a particular shade, but all shades of the same color, which will allow for a more solid segmentation of the entire object.

To illustrate, we begin with this colorful image of Lego bricks that seem fairly easy to segment, due to its multiple areas with mostly solid color. Say, for our example, we want to segment the red blocks in the image, and only the red blocks. Again, simple gray-level thresholding will do no good here as the red blocks may share a similar gray-level intensity with a different-colored block.

![lego.jpg](https://s22.postimg.org/ykztbmgrl/lego.jpg)
*Public domain image from Wikimedia Commons ([link](https://commons.wikimedia.org/wiki/File:Lego_Color_Bricks.jpg))*

To apply NCC in segmentation, we first select a color patch in which we have part of our region of interest (ROI). Here, for the patch, we crop the image to one of the red bricks:

![patchselect.png](https://s22.postimg.org/fnukpi0a9/patchselect.png)

Next, we transform each pixel's RGB into r-g chromaticity values, binning them between some values. By counting the number of pixels that fall in a bin, we can create a two-dimensional histogram of chromaticity values encompassed in the image. The image (a) below is a representation of the chromaticity in each part of the r-g histogram, while (b) is the histogram of our red patch.

![histograms.png](https://s21.postimg.org/p1nda5k9j/histograms.png)

From here, we can break off into two approaches. **Parametric segmentation** involves computing for a two-dimensional Gaussian function with its mean and spread encompassing the histogram values. The gaussian is generated onto a separate r-g space which is backprojected to the original image in the next step. The second approach, **nonparametric segmentation**, requires no further step but directly backprojecting the histogram to the image.

Backprojection involves iterating over each pixel in the original image, computing for its r-g values, and mapping that value in the two-dimensional histogram. The relative intensity of that histogram bin will correspond to the relative gray-level intensity of that pixel location in a new image, which will show the relative correlation the chromaticity of each area in the image with your original image patch.

Shown below are the backprojected results of parametric (a) and nonparametric (b) segmentation, for the selected red color patch (Full resolution images are linked here: [parametric](https://postimg.org/image/pqq9khbu7/), [nonparametric](https://postimg.org/image/dq7wcodn1/)).

![parnparcomp.png](https://s14.postimg.org/bcnixz2xd/parnparcomp.png)

Note that the parametric segmentation is more 'forgiving' in terms of color values that are close to but not at the color values of the image patches, primarily due to the fact that it utilizes a gaussian function centered around the histogram elements of the image patches, creating a wider umbrella of possible color probabilities that can fall into segmentation. In the example segmentation for the color red, this is seen in the left red block, which appears at a higher probability in (a) but much lower in (b). It is important to note that the color patch came from the long red block at the right portion of the image.

We can further reduce this to a binary image on which we may perform further processing via thresholding this gray image at a certain gray-level value. This also reveals a further caveat with regard to choosing parametric or nonparametric segmentation. In the following image, (a) shows the binarized image for our parametric segmentation backprojected histogram. Comparing it with the original color image, we see that the thresholding includes strong elements for the inside of orange bricks, which have a close chromaticity with red. In our segmentation application, we may not want orange bricks to be included; thus, nonparametric segmentation may be a more appropriate method to use. (b) shows the binarized image for nonparametric segmentation. We see that there are fewer areas falling on the orange bricks, which we may remove through further processing.

![parnparbin.png](https://s17.postimg.org/l2y414blr/parnparbin.png)

Segmentation, of course, can be done for any color chromaticity. The following images present a few examples, segmenting following color patches green, yellow, and blue, presenting the histograms and a sample thresholded binary image.

![gby.png](https://s18.postimg.org/yvnbqpw49/gby.png)

Note that artifacts in the histogram images are just due to matrix normalization and conversion to an 8-bit range of values when exporting as an image. The binarized images are not perfect, of course (here the threshold has been automatically selected through [Otsu's method](https://en.wikipedia.org/wiki/Otsu%27s_method)), and better thresholds may be tweaked depending on the application.

We can return to our original case for separating the two different rugby teams. For instance, we can take a red color patch from a red team jersey (a), which results in the histogram backprojected image that highlights all areas of the image with a red chromaticity (b). Thresholding results in mainly red jerseys being selected as the ROI, along with other red elements (c&zwnj;). This segmentation ([full image](https://postimg.org/image/nym1clcv5/)) is markedly beter than the initial gray-level histogram image done earlier in this post.

![rugbyrg.png](https://s21.postimg.org/i2cfx3uqv/rugbyrg.png)

The animation in this post was generated using ImageMagick, with this [forum post](http://www.imagemagick.org/discourse-server/viewtopic.php?t=16144) as a reference for adding the threshold-level counter. All other references and resources linked directly in the text above. Here, I give myself a self-evaluation of **9/10**.
